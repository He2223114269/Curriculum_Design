{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2e9ef9f",
   "metadata": {},
   "source": [
    "# danmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054ded6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "from typing import List, Dict\n",
    "from sklearn.decomposition import NMF\n",
    "from karateclub.estimator import Estimator\n",
    "\n",
    "\n",
    "class DANMF(Estimator):\n",
    "    r\"\"\"An implementation of `\"DANMF\" <https://smartyfh.com/Documents/18DANMF.pdf>`_\n",
    "    from the CIKM '18 paper \"Deep Autoencoder-like Nonnegative Matrix Factorization for\n",
    "    Community Detection\". The procedure uses telescopic non-negative matrix factorization\n",
    "    in order to learn a cluster membership distribution over nodes. The method can be\n",
    "    used in an overlapping and non-overlapping way.\n",
    "\n",
    "    Args:\n",
    "        layers (list): Autoencoder layer sizes in a list of integers. Default [32, 8].\n",
    "        pre_iterations (int): Number of pre-training epochs. Default 100.\n",
    "        iterations (int): Number of training epochs. Default 100.\n",
    "        seed (int): Random seed for weight initializations. Default 42.\n",
    "        lamb (float): Regularization parameter. Default 0.01.\n",
    "        seed (int): Random seed value. Default is 42.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        layers: List[int] = [32, 8],\n",
    "        pre_iterations: int = 100,\n",
    "        iterations: int = 100,\n",
    "        seed: int = 42,\n",
    "        lamb: float = 0.01,\n",
    "    ):\n",
    "        self.layers = layers\n",
    "        self.pre_iterations = pre_iterations\n",
    "        self.iterations = iterations\n",
    "        self.seed = seed\n",
    "        self.lamb = lamb\n",
    "        self._p = len(self.layers)\n",
    "        self.seed = seed\n",
    "\n",
    "    def _setup_target_matrices(self, graph):\n",
    "        \"\"\"\n",
    "        Setup target matrix for pre-training process.\n",
    "\n",
    "        Arg types:\n",
    "            * **graph** *(NetworkX graph)* - The graph being clustered.\n",
    "        \"\"\"\n",
    "        self._graph = graph\n",
    "        self._A = nx.adjacency_matrix(\n",
    "            self._graph, nodelist=range(self._graph.number_of_nodes())\n",
    "        )\n",
    "        self._L = nx.laplacian_matrix(\n",
    "            self._graph, nodelist=range(self._graph.number_of_nodes())\n",
    "        )\n",
    "        self._D = self._L + self._A\n",
    "\n",
    "    def _setup_z(self, i):\n",
    "        \"\"\"\n",
    "        Setup target matrix for pre-training process.\n",
    "\n",
    "        Arg types:\n",
    "            * **i** *(int)* - The layer index.\n",
    "        \"\"\"\n",
    "        if i == 0:\n",
    "            self._Z = self._A\n",
    "        else:\n",
    "            self._Z = self._V_s[i - 1]\n",
    "\n",
    "    def _sklearn_pretrain(self, i):\n",
    "        \"\"\"\n",
    "        Pre-training a single layer of the model with sklearn.\n",
    "\n",
    "        Arg types:\n",
    "            * **i** *(int)* - The layer index.\n",
    "        \"\"\"\n",
    "        nmf_model = NMF(\n",
    "            n_components=self.layers[i],\n",
    "            init=\"random\",\n",
    "            random_state=self.seed,\n",
    "            max_iter=self.pre_iterations,\n",
    "        )\n",
    "\n",
    "        U = nmf_model.fit_transform(self._Z)\n",
    "        V = nmf_model.components_\n",
    "        return U, V\n",
    "\n",
    "    def _pre_training(self):\n",
    "        \"\"\"\n",
    "        Pre-training each NMF layer.\n",
    "        \"\"\"\n",
    "        self._U_s = []\n",
    "        self._V_s = []\n",
    "        for i in range(self._p):\n",
    "            self._setup_z(i)\n",
    "            U, V = self._sklearn_pretrain(i)\n",
    "            self._U_s.append(U)\n",
    "            self._V_s.append(V)\n",
    "\n",
    "    def _setup_Q(self):\n",
    "        \"\"\"\n",
    "        Setting up Q matrices.\n",
    "        \"\"\"\n",
    "        self._Q_s = [None for _ in range(self._p + 1)]\n",
    "        self._Q_s[self._p] = np.eye(self.layers[self._p - 1])\n",
    "        for i in range(self._p - 1, -1, -1):\n",
    "            self._Q_s[i] = np.dot(self._U_s[i], self._Q_s[i + 1])\n",
    "\n",
    "    def _update_U(self, i):\n",
    "        \"\"\"\n",
    "        Updating left hand factors.\n",
    "\n",
    "        Arg types:\n",
    "            * **i** *(int)* - The layer index.\n",
    "        \"\"\"\n",
    "        if i == 0:\n",
    "            R = self._U_s[0].dot(self._Q_s[1].dot(self._VpVpT).dot(self._Q_s[1].T))\n",
    "            R = R + self._A_sq.dot(self._U_s[0].dot(self._Q_s[1].dot(self._Q_s[1].T)))\n",
    "            Ru = 2 * self._A.dot(self._V_s[self._p - 1].T.dot(self._Q_s[1].T))\n",
    "            self._U_s[0] = (self._U_s[0] * Ru) / np.maximum(R, 10**-10)\n",
    "        else:\n",
    "            R = (\n",
    "                self._P.T.dot(self._P)\n",
    "                .dot(self._U_s[i])\n",
    "                .dot(self._Q_s[i + 1])\n",
    "                .dot(self._VpVpT)\n",
    "                .dot(self._Q_s[i + 1].T)\n",
    "            )\n",
    "            R = R + self._A_sq.dot(self._P).T.dot(self._P).dot(self._U_s[i]).dot(\n",
    "                self._Q_s[i + 1]\n",
    "            ).dot(self._Q_s[i + 1].T)\n",
    "            Ru = 2 * self._A.dot(self._P).T.dot(self._V_s[self._p - 1].T).dot(\n",
    "                self._Q_s[i + 1].T\n",
    "            )\n",
    "            self._U_s[i] = (self._U_s[i] * Ru) / np.maximum(R, 10**-10)\n",
    "\n",
    "    def _update_P(self, i):\n",
    "        \"\"\"\n",
    "        Setting up P matrices.\n",
    "\n",
    "        Arg types:\n",
    "            * **i** *(int)* - The layer index.\n",
    "        \"\"\"\n",
    "        if i == 0:\n",
    "            self._P = self._U_s[0]\n",
    "        else:\n",
    "            self._P = self._P.dot(self._U_s[i])\n",
    "\n",
    "    def _update_V(self, i):\n",
    "        \"\"\"\n",
    "        Updating right hand factors.\n",
    "\n",
    "        Arg types:\n",
    "            * **i** *(int)* - The layer index.\n",
    "        \"\"\"\n",
    "        if i < self._p - 1:\n",
    "            Vu = 2 * self._A.dot(self._P).T\n",
    "            Vd = self._P.T.dot(self._P).dot(self._V_s[i]) + self._V_s[i]\n",
    "            self._V_s[i] = self._V_s[i] * Vu / np.maximum(Vd, 10**-10)\n",
    "        else:\n",
    "            Vu = (\n",
    "                2 * self._A.dot(self._P).T + (self.lamb * self._A.dot(self._V_s[i].T)).T\n",
    "            )\n",
    "            Vd = self._P.T.dot(self._P).dot(self._V_s[i])\n",
    "            Vd = Vd + self._V_s[i] + (self.lamb * self._D.dot(self._V_s[i].T)).T\n",
    "            self._V_s[i] = self._V_s[i] * Vu / np.maximum(Vd, 10**-10)\n",
    "\n",
    "    def _setup_VpVpT(self):\n",
    "        self._VpVpT = self._V_s[self._p - 1].dot(self._V_s[self._p - 1].T)\n",
    "\n",
    "    def _setup_Asq(self):\n",
    "        self._A_sq = self._A.dot(self._A.T)\n",
    "\n",
    "    def get_embedding(self) -> np.array:\n",
    "        r\"\"\"Getting the bottleneck layer embedding.\n",
    "\n",
    "        Return types:\n",
    "            * **embedding** *(Numpy array)* - The bottleneck layer embedding of nodes.\n",
    "        \"\"\"\n",
    "        embedding = [self._P, self._V_s[-1].T]\n",
    "        embedding = np.concatenate(embedding, axis=1)\n",
    "        return embedding\n",
    "\n",
    "    def get_memberships(self) -> Dict[int, int]:\n",
    "        r\"\"\"Getting the cluster membership of nodes.\n",
    "\n",
    "        Return types:\n",
    "            * **memberships** *(dict)*: Node cluster memberships.\n",
    "        \"\"\"\n",
    "        index = np.argmax(self._P, axis=1)\n",
    "        memberships = {int(i): int(index[i]) for i in range(len(index))}\n",
    "        return memberships\n",
    "\n",
    "    def fit(self, graph: nx.classes.graph.Graph):\n",
    "        \"\"\"\n",
    "        Fitting a DANMF clustering model.\n",
    "\n",
    "        Arg types:\n",
    "            * **graph** *(NetworkX graph)* - The graph to be clustered.\n",
    "        \"\"\"\n",
    "        self._set_seed()\n",
    "        graph = self._check_graph(graph)\n",
    "        self._setup_target_matrices(graph)\n",
    "        self._pre_training()\n",
    "        self._setup_Asq()\n",
    "        for iteration in range(self.iterations):\n",
    "            self._setup_Q()\n",
    "            self._setup_VpVpT()\n",
    "            for i in range(self._p):\n",
    "                self._update_U(i)\n",
    "                self._update_P(i)\n",
    "                self._update_V(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f1d8c7",
   "metadata": {},
   "source": [
    "# mnmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9611df39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "from typing import Dict\n",
    "from scipy.sparse import coo_matrix\n",
    "from karateclub.estimator import Estimator\n",
    "\n",
    "\n",
    "class MNMF(Estimator):\n",
    "    r\"\"\"An implementation of `\"M-NMF\" <https://aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14589/13763>`_\n",
    "    from the AAAI '17 paper \"Community Preserving Network Embedding\".\n",
    "    The procedure uses joint non-negative matrix factorization with modularity\n",
    "    based regularization in order to learn a cluster membership distribution\n",
    "    over nodes. The method can be used in an overlapping and non-overlapping way.\n",
    "\n",
    "    Args:\n",
    "        dimensions (int): Number of dimensions. Default is 128.\n",
    "        clusters (int): Number of clusters. Default is 10.\n",
    "        lambd (float): KKT penalty. Default is 0.2\n",
    "        alpha (float): Clustering penalty. Default is 0.05.\n",
    "        beta (float): Modularity regularization penalty. Default is 0.05.\n",
    "        iterations (int): Number of power iterations. Default is 200.\n",
    "        lower_control (float): Floating point overflow control. Default is 10**-15.\n",
    "        eta (float): Similarity mixing parameter. Default is 5.0.\n",
    "        seed (int): Random seed value. Default is 42.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dimensions: int = 128,\n",
    "        clusters: int = 10,\n",
    "        lambd: float = 0.2,\n",
    "        alpha: float = 0.05,\n",
    "        beta: float = 0.05,\n",
    "        iterations: int = 200,\n",
    "        lower_control: float = 10**-15,\n",
    "        eta: float = 5.0,\n",
    "        seed: int = 42,\n",
    "    ):\n",
    "\n",
    "        self.dimensions = dimensions\n",
    "        self.clusters = clusters\n",
    "        self.lambd = lambd\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.iterations = iterations\n",
    "        self.lower_control = lower_control\n",
    "        self.eta = eta\n",
    "        self.seed = seed\n",
    "\n",
    "    def _modularity_generator(self):\n",
    "        \"\"\"Calculating the sparse modularity matrix.\"\"\"\n",
    "        degs = nx.degree(self._graph)\n",
    "        e_count = self._graph.number_of_edges()\n",
    "        n_count = self._graph.number_of_nodes()\n",
    "        modularity_mat_shape = (n_count, n_count)\n",
    "        indices_1 = np.array(\n",
    "            [edge[0] for edge in self._graph.edges()]\n",
    "            + [edge[1] for edge in self._graph.edges()]\n",
    "        )\n",
    "        indices_2 = np.array(\n",
    "            [edge[1] for edge in self._graph.edges()]\n",
    "            + [edge[0] for edge in self._graph.edges()]\n",
    "        )\n",
    "        scores = [\n",
    "            float(degs[e[0]] * degs[e[1]]) / (2 * e_count) for e in self._graph.edges()\n",
    "        ]\n",
    "        scores = scores + [\n",
    "            float(degs[e[1]] * degs[e[0]]) / (2 * e_count) for e in self._graph.edges()\n",
    "        ]\n",
    "        mod_matrix = coo_matrix(\n",
    "            (scores, (indices_1, indices_2)), shape=modularity_mat_shape\n",
    "        )\n",
    "        return mod_matrix\n",
    "\n",
    "    def _setup_matrices(self):\n",
    "        \"\"\"Creating parameter matrices and target matrices.\"\"\"\n",
    "        self._number_of_nodes = nx.number_of_nodes(self._graph)\n",
    "        self._M = np.random.uniform(0, 1, (self._number_of_nodes, self.dimensions))\n",
    "        self._U = np.random.uniform(0, 1, (self._number_of_nodes, self.dimensions))\n",
    "        self._H = np.random.uniform(0, 1, (self._number_of_nodes, self.clusters))\n",
    "        self._C = np.random.uniform(0, 1, (self.clusters, self.dimensions))\n",
    "        self._B1 = nx.adjacency_matrix(\n",
    "            self._graph, nodelist=range(self._graph.number_of_nodes())\n",
    "        )\n",
    "        self._B2 = self._modularity_generator()\n",
    "        self._X = np.transpose(self._U)\n",
    "        overlaps = self._B1.dot(self._B1)\n",
    "        self._S = self._B1 + self.eta * self._B1 * (overlaps)\n",
    "\n",
    "    def _update_M(self):\n",
    "        \"\"\"Update matrix M.\"\"\"\n",
    "        enum = self._S.dot(self._U)\n",
    "        denom = np.dot(self._M, np.dot(np.transpose(self._U), self._U))\n",
    "        denom[denom < self.lower_control] = self.lower_control\n",
    "        self._M = np.multiply(self._M, enum / denom)\n",
    "        row_sums = self._M.sum(axis=1)\n",
    "        self._M = self._M / row_sums[:, np.newaxis]\n",
    "\n",
    "    def _update_U(self):\n",
    "        \"\"\"Update matrix U.\"\"\"\n",
    "        enum = self._S.dot(self._M) + self.alpha * np.dot(self._H, self._C)\n",
    "        denom = np.dot(\n",
    "            self._U,\n",
    "            np.dot(np.transpose(self._M), self._M)\n",
    "            + self.alpha * np.dot(np.transpose(self._C), self._C),\n",
    "        )\n",
    "        denom[denom < self.lower_control] = self.lower_control\n",
    "        self._U = np.multiply(self._U, enum / denom)\n",
    "        row_sums = self._U.sum(axis=1)\n",
    "        self._U = self._U / row_sums[:, np.newaxis]\n",
    "\n",
    "    def _update_C(self):\n",
    "        \"\"\"Update matrix C.\"\"\"\n",
    "        enum = np.dot(np.transpose(self._H), self._U)\n",
    "        denom = np.dot(self._C, np.dot(np.transpose(self._U), self._U))\n",
    "        denom[denom < self.lower_control] = self.lower_control\n",
    "        frac = enum / denom\n",
    "        self._C = np.multiply(self._C, frac)\n",
    "        row_sums = self._C.sum(axis=1)\n",
    "        self._C = self._C / row_sums[:, np.newaxis]\n",
    "\n",
    "    def _update_H(self):\n",
    "        \"\"\"Update matrix H.\"\"\"\n",
    "        B1H = self._B1.dot(self._H)\n",
    "        B2H = self._B2.dot(self._H)\n",
    "        HHH = np.dot(self._H, (np.dot(np.transpose(self._H), self._H)))\n",
    "        UC = np.dot(self._U, np.transpose(self._C))\n",
    "        rooted = np.square(2 * self.beta * B2H) + np.multiply(\n",
    "            16 * self.lambd * HHH,\n",
    "            (\n",
    "                2 * self.beta * B1H\n",
    "                + 2 * self.alpha * UC\n",
    "                + (4 * self.lambd - 2 * self.alpha) * self._H\n",
    "            ),\n",
    "        )\n",
    "        rooted[rooted < 0] = 0\n",
    "        sqroot_1 = np.sqrt(rooted)\n",
    "        enum = -2 * self.beta * B2H + sqroot_1\n",
    "        denom = 8 * self.lambd * HHH\n",
    "        denom[denom < self.lower_control] = self.lower_control\n",
    "        rooted = enum / denom\n",
    "        rooted[rooted < 0] = 0\n",
    "        sqroot_2 = np.sqrt(rooted)\n",
    "        self._H = np.multiply(self._H, sqroot_2)\n",
    "        row_sums = self._H.sum(axis=1)\n",
    "        self._H = self._H / row_sums[:, np.newaxis]\n",
    "\n",
    "    def get_memberships(self) -> Dict[int, int]:\n",
    "        r\"\"\"Getting the cluster membership of nodes.\n",
    "\n",
    "        Return types:\n",
    "            * **memberships** *(dict)* - Node cluster memberships.\n",
    "        \"\"\"\n",
    "        indices = np.argmax(self._H, axis=1)\n",
    "        memberships = {i: membership for i, membership in enumerate(indices)}\n",
    "        return memberships\n",
    "\n",
    "    def get_embedding(self) -> np.array:\n",
    "        r\"\"\"Getting the node embedding.\n",
    "\n",
    "        Return types:\n",
    "            * **embedding** *(Numpy array)* - The embedding of nodes.\n",
    "        \"\"\"\n",
    "        embedding = self._U\n",
    "        return embedding\n",
    "\n",
    "    def get_cluster_centers(self) -> np.array:\n",
    "        r\"\"\"Getting the node embedding.\n",
    "\n",
    "        Return types:\n",
    "            * **centers** *(Numpy array)* - The cluster centers.\n",
    "        \"\"\"\n",
    "        centers = self._C\n",
    "        return centers\n",
    "\n",
    "    def fit(self, graph: nx.classes.graph.Graph):\n",
    "        \"\"\"\n",
    "        Fitting an M-NMF clustering model.\n",
    "\n",
    "        Arg types:\n",
    "            * **graph** *(NetworkX graph)* - The graph to be clustered.\n",
    "        \"\"\"\n",
    "        self._set_seed()\n",
    "        graph = self._check_graph(graph)\n",
    "        self._graph = graph\n",
    "        self._setup_matrices()\n",
    "        for _ in range(self.iterations):\n",
    "            self._update_M()\n",
    "            self._update_U()\n",
    "            self._update_C()\n",
    "            self._update_H()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10ea648",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f954d26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34070e31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06248d4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608b3350",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268b3cda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8902ce7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60573fde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e300017",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9bbc2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb0953b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e197004",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46843dab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e451e3ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ad5adf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
