{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4724344a",
   "metadata": {},
   "source": [
    "# 第三次实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e53cc4e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stocGradAscent1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10060\\1118616489.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"10次算法测试后平均错误率为：{:.2%}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merrorSum\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumTests\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m     \u001b[0mmultiTest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10060\\1118616489.py\u001b[0m in \u001b[0;36mmultiTest\u001b[1;34m()\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;31m# 通过10次的算法测试，并获得10次错误率的总和\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumTests\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         \u001b[0merrorSum\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mcolicTest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m     \u001b[1;31m# 通过错误率总和/10可以求得10次平均错误率并输出\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"10次算法测试后平均错误率为：{:.2%}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merrorSum\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumTests\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10060\\1118616489.py\u001b[0m in \u001b[0;36mcolicTest\u001b[1;34m()\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mtrainingLabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrLine\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m21\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;31m# 使用上面写的改进的随机梯度算法求得最佳系数，用于下面分类器使用区分类型\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m     \u001b[0mtrainWeights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstocGradAscent1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainingSet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainingLabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m     \u001b[0merrorCount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[0mnumTestVec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stocGradAscent1' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "data=pd.read_csv('testset.csv',encoding =\"utf-8\",header = None)\n",
    "data = data.iloc[0:17,1:4]\n",
    "df = pd.DataFrame(data)\n",
    "label=df.iloc[:,2]\n",
    "x1=df.iloc[:,0]\n",
    "x2=df.iloc[:,1]\n",
    "train_data=list(zip(x1,x2,label))\n",
    "class Logistic_Regression:\n",
    "    def __init__(self,traindata,alpha=0.001,circle=1000,batchlength=40):\n",
    "        self.traindata=traindata #训练数据集\n",
    "        self.alpha=alpha #学习率\n",
    "        self.circle=circle #学习次数\n",
    "        self.batchlength=batchlength #把3349个数据分成多个部分，每个部分有batchlength个数据\n",
    "        self.w=np.random.normal(size=(3,1)) #随机初始化参数w\n",
    "    def data_process(self):\n",
    "        '''做随机梯度下降，打乱数据顺序，并把所有数据分成若干个batch'''\n",
    "        np.random.shuffle(self.traindata)\n",
    "        data=[self.traindata[i:i+self.batchlength]\n",
    "              for i in range(0,len(self.traindata),self.batchlength)]\n",
    "        return data\n",
    "    def train1(self):\n",
    "        '''根据损失函数（1）来进行梯度下降，这里采用随机梯度下降'''\n",
    "        for i in range(self.circle):\n",
    "            batches=self.data_process()\n",
    "            print('the {} epoch'.format(i)) #程序运行时显示执行次数\n",
    "            for batch in batches:\n",
    "                d_w=np.zeros(shape=(3,1)) #用来累计w导数值\n",
    "                for j in batch: #取batch中每一组数据\n",
    "                    x0=np.r_[j[0:2],1] #把数据中指标取出，后面补1\n",
    "                    x=np.mat(x0).T #转化成列向量\n",
    "                    y=j[2] #标签\n",
    "                    dw=(self.sigmoid(self.w.T*x)-y)[0,0]*x\n",
    "                    d_w+=dw\n",
    "                self.w-=self.alpha*d_w/self.batchlength\n",
    " \n",
    "    def train2(self):\n",
    "        '''用均方损失函数来进行梯度下降求解'''\n",
    "        for i in range(self.circle):\n",
    "            batches=self.data_process()\n",
    "            print('the {} epoch'.format(i)) #程序运行时显示执行次数\n",
    "            for batch in batches:\n",
    "                d_w=np.zeros(shape=(3,1)) #用来累计w导数值\n",
    "                for j in batch: #取batch中每一组数据\n",
    "                    x0=np.r_[j[0:2],1] #把数据中指标取出，后面补1\n",
    "                    x=np.mat(x0).T #转化成列向量\n",
    "                    y=j[2] #标签\n",
    "                    dw=((self.sigmoid(self.w.T*x)-y)*self.sigmoid(self.w.T*x)*(1-self.sigmoid(self.w.T*x)))[0,0]*x\n",
    "                    d_w+=dw\n",
    "                self.w-=self.alpha*d_w/self.batchlength\n",
    "   \n",
    "    def sigmoid(self,x):\n",
    "        return 1/(1+np.exp(-x))\n",
    " \n",
    "    def predict(self,x):\n",
    "        '''测试新数据属于哪一类，x是2维列向量'''\n",
    "        s=self.sigmoid(self.w.T*x)\n",
    "        if s>=0.5:\n",
    "            return 1\n",
    "        elif s<0.5:\n",
    "            return 0\n",
    "if __name__=='__main__':\n",
    "    regr=Logistic_Regression(traindata=train_data)\n",
    "    regr.train1() #采用1的方式进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7183d82d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4519b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93869acb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0b88da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd541c0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
